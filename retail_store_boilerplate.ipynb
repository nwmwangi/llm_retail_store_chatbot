{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bb9605",
   "metadata": {},
   "source": [
    "## Here, we build an llm model that queries a SQL Database using human like language, then the model converts this into a SQL QUERY and returns the required results. Here is the boiler plate code for the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d50c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30449e33",
   "metadata": {},
   "source": [
    "#### Import sll the required libraries and the packages. Ensure you have installed the libraries from the requirements.txt file by running the command ==> pip install -r requirements.txt from the command line or ==> !pip install -r requirements.txt here on the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae66a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.chains import sql_database\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain.chains.sql_database.prompt import PROMPT_SUFFIX, _postgres_prompt\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbc8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e12aba",
   "metadata": {},
   "source": [
    "#### create an llm object and pass the api key. Be sure to keep your api key as a secret away from the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78cfead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_object = GooglePalm(google_api_key=api_key, temperature=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7900d8",
   "metadata": {},
   "source": [
    "#### create a SQL Database object by importing SQLDatabase class from langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ad0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = 'postgres'\n",
    "db_password = 'postgres123'\n",
    "db_host = 'localhost'\n",
    "db_name = 'retail_store'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166ed46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(f'postgresql+psycopg2://postgres:postgres123@localhost:5433/retail_store',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ecfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:5433/{db_name}',sample_rows_in_table_info=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db492fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE fmcg_retail_goods (\n",
      "\tid SERIAL NOT NULL, \n",
      "\titem VARCHAR(60) NOT NULL, \n",
      "\tstock_quantity INTEGER NOT NULL, \n",
      "\tprice INTEGER NOT NULL, \n",
      "\tCONSTRAINT fmcg_retail_goods_pkey PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from fmcg_retail_goods table:\n",
      "id\titem\tstock_quantity\tprice\n",
      "1\tSugar\t5\t240\n",
      "2\tArimis Milking Salve\t5\t40\n",
      "3\tSkala Petroleum Jelly\t5\t45\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70913d75",
   "metadata": {},
   "source": [
    "#### Create a SQL database chain object, and run simple SQL Query. We set verbosity to True to enable us view the Query being generated by the SQL chain. The default output is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d245781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b279b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "what is the price of 64 pages book?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT price FROM fmcg_retail_goods WHERE item = '64 pages book'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m240\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain.from_llm(llm_object, db, verbose=True)\n",
    "qns1 = db_chain.run(\"what is the price of 64 pages book?\")\n",
    "# qns2 = db_chain.run(\"what is the lowest paid salary of an employee and what is their title?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9826968",
   "metadata": {},
   "source": [
    "#### For simple queries, the llm objects works fine as expected, however it's not in a position to generate complex queries that involve multiple table columns or tables. To prevent the llm object giving back wrong output or hallucinating, we can pretrain it through fewshots learning where we create the complex queries ourselves and feed the queries to the llm object as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f2506a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "\n",
    "HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bc256",
   "metadata": {},
   "source": [
    "#### We then create few shot embeddings, and for that we import the hugging face embeddings. Basically, embeddings captures the true meaning of a given query and stores it in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b5e5b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bda8f",
   "metadata": {},
   "source": [
    "#### create a few shot of sql queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42624a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shots = [\n",
    "{\n",
    "\t\"Question\": \"How many eden tea do we have left for 50g?\",\n",
    "\t'SQLQuery': \"SELECT sum(stock_quantity) FROM fmcg_retail_goods where item='Eden Tea 50g' \",\n",
    "\t'SQLResult': \"Result of the SQL query\",\n",
    "\t'Answer': 'qns1' },\n",
    "\t{\n",
    "\t\"Question\": \"How much is the total price of the inventory for all 2kgs Ngano flour?\",\n",
    "\t'SQLQuery': \"SELECT sum(price * stock_quantity) FROM fmcg_retail_goods where item='Ngano Flour 2kgs'\",\n",
    "\t'SQLResult': \"Result of the SQL query\",\n",
    "\t'Answer': 'qns2' },\n",
    "{\n",
    "\t\"Question\": \"If we have to sell all the tissue in the store today, how much revenue will be generated?\",\n",
    "\t'SQLQuery': \"SELECT sum(price * stock_quantity) FROM fmcg_retail_goods where item='Tissue'\",\n",
    "\t'SQLResult': \"Result of the SQL query\",\n",
    "\t'Answer': 'qns3' },\n",
    "\n",
    "\t{\n",
    "\t\"Question\": \"If we have to sell all the items in our inventory how much revenue will be generated?\",\n",
    "\t'SQLQuery': \"SELECT sum(price * stock_quantity) FROM fmcg_retail_goods \",\n",
    "\t'SQLResult': \"Result of the SQL query\",\n",
    "\t'Answer': 'qns4' },\n",
    "\n",
    "\t{\n",
    "\t\"Question\": \"how many ordinary biro pen do we have left in stock?\",\n",
    "\t'SQLQuery': \"SELECT sum(stock_quantity) FROM fmcg_retail_goods where item='Ordinary Biro Pen'\",\n",
    "\t'SQLResult': \"Result of the SQL query\",\n",
    "\t'Answer': 'qns5' },\n",
    "\n",
    "\t{\n",
    "\t\"Question\": \"What is the running total of each item type in the inventory?\",\n",
    "\t'SQLQuery': \"SELECT id, item, sum(price*stock_quantity) OVER (PARTITION BY item order by 3) AS running_total from fmcg_retail_goods\",\n",
    "\t'SQLResult': \"Result of the SQL query\",\n",
    "\t'Answer': 'qns6' }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1952f",
   "metadata": {},
   "source": [
    "#### vectorize the few shots into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f31fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_vectorize = [' '.join(shot.values()) for shot in few_shots]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b0cae",
   "metadata": {},
   "source": [
    "#### Store the vectors into a vector database, here we are going to use the chroma vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c8276d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfadee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6212f5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61040421",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(shots_vectorize,\n",
    "                            embedding=embeddings,\n",
    "                            metadatas=few_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd476c4",
   "metadata": {},
   "source": [
    "#### With embeddings, llm can now match similar questions even when they have different wordings, for that we import the SemanticSimilartiyExample Selector and pass in the created vectore store and a variable k, with your oreffered number of examples you would like returned, for this case, we are going to work with two examples hence: k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50f9babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SemanticSimilarityExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac16b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Answer': 'qns4',\n",
       "  'Question': 'If we have to sell all the items in our inventory how much revenue will be generated?',\n",
       "  'SQLQuery': 'SELECT sum(price * stock_quantity) FROM fmcg_retail_goods ',\n",
       "  'SQLResult': 'Result of the SQL query'},\n",
       " {'Answer': 'qns3',\n",
       "  'Question': 'If we have to sell all the tissue in the store today, how much revenue will be generated?',\n",
       "  'SQLQuery': \"SELECT sum(price * stock_quantity) FROM fmcg_retail_goods where item='Tissue'\",\n",
       "  'SQLResult': 'Result of the SQL query'},\n",
       " {'Answer': 'qns6',\n",
       "  'Question': 'What is the running total of each item type in the inventory?',\n",
       "  'SQLQuery': 'SELECT id, item, sum(price*stock_quantity) OVER (PARTITION BY item order by 3) AS running_total from fmcg_retail_goods',\n",
       "  'SQLResult': 'Result of the SQL query'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_select = SemanticSimilarityExampleSelector(vectorstore=vectorstore, k=3)\n",
    "\n",
    "sample_select.select_examples({'Question':'What is the total revenue of all the items in store?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674ed87",
   "metadata": {},
   "source": [
    "#### There are scenarios where the llm objects outputs results from its previous knowledge or stored memory away from the set knowledge base in our case the provided SQL Database, to curb this, langchain provides PROMPT classes through which we can set clear instruction to llm to strictly use the provided database columns and draw answers only from the provided table. For that we import postgres prompt class since we are using PostgreSQL database and the suffix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245b667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sql_database.prompt import PROMPT_SUFFIX, _postgres_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bbf06e",
   "metadata": {},
   "source": [
    "#### We also need to import the prompt template to give us the format of the query prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cd1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "sample_prompt = PromptTemplate(\n",
    "    input_variables=[\"Question\", \"SQLQuery\", \"SQLResult\", \"Answer\",],\n",
    "    template=\"\\nQuestion:{Question}\\nSQLQuery:{SQLQuery}\\nSQLResult:{SQLResult}\\nAnswer:{Answer}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d41454",
   "metadata": {},
   "source": [
    "#### And then we create a fewshot template by first importing the fewshot prompt template from langchain prompts. Fewshot template establishes a connection between the created llm object and the provided vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4264fb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['input', 'table_info', 'top_k'], example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x000002A9062EF0D0>, k=3, example_keys=None, input_keys=None), example_prompt=PromptTemplate(input_variables=['Answer', 'Question', 'SQLQuery', 'SQLResult'], template='\\nQuestion:{Question}\\nSQLQuery:{SQLQuery}\\nSQLResult:{SQLResult}\\nAnswer:{Answer}'), suffix='Only use the following tables:\\n{table_info}\\n\\nQuestion: {input}', prefix='You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\n')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "FewShotPromptTemplate(\n",
    "    example_selector = sample_select,\n",
    "    example_prompt = sample_prompt,\n",
    "    prefix = _postgres_prompt,\n",
    "    suffix = PROMPT_SUFFIX,\n",
    "    input_variables = [\"input\", \"table_info\", \"top_k\"],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d14d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "606aa53f",
   "metadata": {},
   "source": [
    "#### Now we create the llm chain and issue a few shot prompt from where the llm object can reference in case a question is confusing or difficult to comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b115656",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chain = SQLDatabaseChain.from_llm(llm_object, db, verbose=True, prompt=sample_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c18d8f",
   "metadata": {},
   "source": [
    "### Now we can use these code from the jupyter playground to create a simple streamlit app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad211f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
